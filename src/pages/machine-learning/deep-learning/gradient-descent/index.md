---
title: Gradient Descent
---
## Gradient Descent
<!-- The article goes here, in GitHub-flavored Markdown. Feel free to add YouTube videos, images, and CodePen/JSBin embeds  -->
Gradient descent is a popularly used optimization algorithm. It is used in finding the "minima" of a function. Gradient descent is iterative first-order optimization algorithm. In order to find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.<sup>1</sup>

#### More Information:
<!-- Please add any articles you think might be helpful to read before writing the article -->
[A guide to Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)

### Sources:

1. [Wikipedia](https://en.wikipedia.org/wiki/Gradient_descent)


