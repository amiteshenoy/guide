---
title: Gradient Descent
---
## Gradient Descent
<!-- The article goes here, in GitHub-flavored Markdown. Feel free to add YouTube videos, images, and CodePen/JSBin embeds  -->
Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point. Gradient descent is also known as steepest descent. However, gradient descent should not be confused with the method of steepest descent for approximating integrals. <sup>1</sup>

#### More Information:
<!-- Please add any articles you think might be helpful to read before writing the article -->
[A guide to Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)

### Sources:

1. [Wikipedia](https://en.wikipedia.org/wiki/Gradient_descent)


